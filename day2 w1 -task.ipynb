{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c65557-20ee-4ac4-a47b-1aba3630f2f4",
   "metadata": {},
   "source": [
    "# Using llama 3.2 to build a website summarizer that runs on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "888bf366-cc32-414f-8ada-d3e3b869f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e26082-b6f4-49f6-8b0f-c98c5140cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1322d3-6a04-4ee9-9667-9f691d4ff3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 74701a8c35f6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.3 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 4f659a1e86d7... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Downloads the Llama 3.2 model (1B parameters) from Ollama to local system.\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f8cbfa-d8aa-41ab-9fc9-da721d6fa32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dc9dd7-4e4f-45e4-bf1f-6cb0d609d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40edb9ac-973c-4861-b2d4-de3eaf30aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5f9e0c-dc46-4344-b9c8-913dec312d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates messages list\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db123581-10b1-4b6f-8c4b-8548c59292d9",
   "metadata": {},
   "source": [
    "#### Calling llama 3.2 using requests API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b505ee2-1d63-4a5f-a375-a0bb9daed2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create custom payloads\n",
    "def payload_for(website):\n",
    "    return {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages_for(website),\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514a487d-8293-4862-bd68-46512bdb6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: calling llama using requests\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = requests.post(OLLAMA_API, json=payload_for(website), headers=HEADERS)\n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396927c2-202b-4a10-8a8a-a411153307a4",
   "metadata": {},
   "source": [
    "#### Calling llama 3.2 using ollama package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab18c3ef-43f7-4546-96cc-fa9f06f20c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling llama using ollama package\n",
    "\n",
    "import ollama\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(model=MODEL, messages=messages_for(website))\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db02ab7-7ca9-4e43-bdae-763e0c4364f1",
   "metadata": {},
   "source": [
    "#### Calling llama 3.2 using Open AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae2462bc-cfbd-4a71-8264-7a38a226f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling llama using OpenAI's API\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52007601-f77e-4903-9c5a-de44f73e6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calls summarize function and outputs a summary in Markdown format\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48afd58-1fda-4422-844f-0544be0684dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The article discusses the current market trends and outlook, including:\n",
       "\n",
       "1. **NVIDIA (NVDA) stock**: The company's recent earnings report showed a strong performance, with a 63% increase in quarterly revenue.\n",
       "2. **Alibaba Group Holding Limited (BABA)**: The Chinese conglomerate's stock was trading at $140.11, up 0.88%, driven by strong demand for its cloud computing and e-commerce platforms.\n",
       "3. **Dow Jones Industrial Average (DJIA) index**: The overall market sentiment remains cautious, with investors waiting for the Federal Reserve to announce its monetary policy decisions.\n",
       "\n",
       "However, there are also some concerns:\n",
       "\n",
       "1. **Tariffs and trade tensions**: Trade wars and tariffs between countries have raised uncertainty about global economic growth.\n",
       "2. **Global inflation**: Inflation has been rising in various parts of the world, posing challenges for central banks and policymakers.\n",
       "3. **Cryptocurrency market volatility**: Cryptocurrencies have experienced significant price fluctuations in recent days, affecting investors who hold cryptocurrencies.\n",
       "\n",
       "To navigate these complexities, it's essential to:\n",
       "\n",
       "1. **Monitor economic indicators**: Keep an eye on key indicators such as inflation rates, employment numbers, and GDP growth.\n",
       "2. **Stay informed about trade policies**: Be aware of the ongoing trade tensions between countries and how they might impact your investments.\n",
       "3. **Diversify your portfolio**: Consider spreading your investments across various asset classes to minimize risks.\n",
       "\n",
       "Overall, while there are some concerns in the market, the overall trend remains positive, with growth stocks like NVIDIA (NVDA) and Alibaba Group Holding Limited (BABA) continuing to perform well."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary('https://finance.yahoo.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116f73da-9305-4fa5-bfdd-f4dbb3e43af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Reddit - Dive into Anything**\n",
       "\n",
       "This subreddit is a platform where users can share and discuss various topics, including news, entertainment, sports, and more. The site has a vast array of content, including articles, discussions, and live streams.\n",
       "\n",
       "**News and Announcements**\n",
       "\n",
       "* A Canadian team won the Four Nations hockey tournament, with Connor McDavid scoring the winning goal.\n",
       "* TruGreen, an official lawn care treatment provider for the PGA TOUR, is promoting its services through a special offer.\n",
       "* Severance, an Apple TV+ series, has received positive reviews for its unique storyline and performances.\n",
       "\n",
       "**Popular Communities**\n",
       "\n",
       "* r/AskMen: A community focused on male relationships and advice.\n",
       "* r/NBA2k: A subreddit dedicated to basketball video games, with discussions and polls.\n",
       "* r/MadeMeSmile: A community where users share things that brighten up their day or make them smile."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary('https://reddit.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc24a7d8-fd4a-443e-b4e2-c9c7aa3b3bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Learn Web Scraping | Scrape This Site\n",
       "#### A Public Sandbox for Learning Web Scraping\n",
       "\n",
       "*   **Sandbox**: A resource where users can practice web scraping by browsing a public database of NHL team stats since 1990.\n",
       "*   **Lessons**: Provides hands-on experience with web scraping and data extraction from popular websites like Countries of the World, Hockey Teams, Oscar Winning Films, and Turtles All the Way Down. Each lesson aims to cover specific techniques or concepts related to web scraping, such as navigating different website interface components and handling common network errors.\n",
       "*   **FAQ**: Offers general questions and answers about web scraping, navigation, and other related topics.\n",
       "*   **Login**: A feature for users who want to access the site's advanced features without exposing their login credentials."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary('https://www.scrapethissite.com/pages/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
