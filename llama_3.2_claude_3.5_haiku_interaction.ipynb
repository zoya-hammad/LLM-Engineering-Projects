{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e063b35e-5598-4084-b255-89956bfedaac",
   "metadata": {},
   "source": [
    "### Models an interaction between LLama 3.2 and Claude 3.5 Haiku\n",
    "- Llama 3.2 used via Ollama locally\n",
    "- Claude used via Anthropic API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f534359-cdb4-4441-aa66-d6700fa4d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdff240-9118-4061-9369-585c4d4ce0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "   \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff110b3f-3986-4fd8-a0b1-fd4b51133a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Anthropic\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e596c6-6307-49c1-a29f-5c4e88f8d34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 74701a8c35f6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.3 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 4f659a1e86d7... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Download the llama3.2:1b model for local execution.\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633b6892-6d04-40cb-8b61-196fc754b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "CLAUDE_MODEL = \"claude-3-5-haiku-latest\"\n",
    "LLAMA_MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a699a809-e3d3-4392-94bd-e2f80a5aec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_system = \"You are a chatbot designed as a study tutor for undergraduate students. \\\n",
    "You explain information and key-technical terms related to the subject in a succint yet \\\n",
    "comprehensive manner. You may use tables, formatting and other visuals to help create \\\n",
    "'cheat-sheets' of sorts.\"\n",
    "\n",
    "llama_system = \"You are a chatbot designed to ask questions about different topics related to \\\n",
    "computer vision. You are meant to simulate a student, not teacher. Act as if you have no \\\n",
    "prior knowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb049d8-130b-42dd-aaab-29c09e3e2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_messages = [\"Hi\"]\n",
    "claude_messages = [\"Hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c158f31c-5e8b-48a4-9980-6b280393800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llama():\n",
    "    messages = [{\"role\": \"system\", \"content\": llama_system}]\n",
    "    for llama_msg, claude_msg in zip(llama_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": llama_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude_msg})\n",
    "    response = ollama.chat(model=LLAMA_MODEL, messages=messages)\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d803c5a2-df54-427a-9b80-8e9dd04ee36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for llama_msg, claude_msg in zip(llama_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": llama_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": llama_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=CLAUDE_MODEL,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23794bb-0f36-4f91-aa28-24b876203a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's on your mind today? Are you studying computer vision and want to practice asking me questions, or is there something specific that's been bugging you about it?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_llama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f5c3e2f-a1bb-403b-b6b5-944a10d93305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi there! I'm your study tutor assistant. What subject or topic would you like help understanding today? I'm ready to break down complex concepts, create study guides, explain technical terms, or help you prepare for exams. What can I help you with?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6eb874-1c8f-47d8-a9f1-2e0fe197ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama:\n",
      "Hi\n",
      "Claude:\n",
      "Hello there, what would you like to learn today?\n",
      "Llama 3.2:\n",
      "I'm feeling curious! I'd love to know more about the basics of computer vision and how it's used in real-world applications. What are some common tasks that people do with computer vision, like in their daily lives?\n",
      "Claude 3.5 Haiku:\n",
      "Great question! Let me break down Computer Vision (CV) in an easy-to-understand format:\n",
      "\n",
      "📸 Computer Vision Basics\n",
      "\n",
      "Definition:\n",
      "- A field of AI that enables computers to understand and interpret visual information from images/videos\n",
      "- Mimics human visual perception using machine learning and deep learning techniques\n",
      "\n",
      "🔍 Common Computer Vision Tasks:\n",
      "\n",
      "1. Image Classification\n",
      "- Identifying what's in an image\n",
      "- Examples: \n",
      "  * Smartphone face recognition\n",
      "  * Social media photo tagging\n",
      "  * Medical image diagnosis\n",
      "\n",
      "2. Object Detection\n",
      "- Locating and identifying specific objects in an image\n",
      "- Examples:\n",
      "  * Self-driving car lane/pedestrian detection\n",
      "  * Retail inventory tracking\n",
      "  * Security camera monitoring\n",
      "\n",
      "3. Facial Recognition\n",
      "- Identifying or verifying a person's identity\n",
      "- Examples:\n",
      "  * iPhone Face ID\n",
      "  * Airport security\n",
      "  * Social media photo suggestions\n",
      "\n",
      "4. Augmented Reality\n",
      "- Overlaying digital information on real-world visuals\n",
      "- Examples:\n",
      "  * Snapchat filters\n",
      "  * IKEA furniture placement app\n",
      "  * Pokemon GO game\n",
      "\n",
      "5. Image Segmentation\n",
      "- Dividing images into meaningful segments\n",
      "- Examples:\n",
      "  * Medical image analysis\n",
      "  * Satellite imagery interpretation\n",
      "  * Autonomous vehicle navigation\n",
      "\n",
      "Would you like me to elaborate on any of these areas?\n",
      "Llama 3.2:\n",
      "Wow, that's a comprehensive breakdown! I'm feeling more and more interested in computer vision.\n",
      "\n",
      "Just to clarify, I'd like to ask some questions to make sure I understand the concepts correctly:\n",
      "\n",
      "1. Image Classification is about identifying specific things (like faces or objects) in an image. Can you give me some examples of what this can be used for?\n",
      "2. Object Detection involves finding and locating specific objects within an image. What kind of objects would be useful for self-driving cars to detect, like lane lines or pedestrians?\n",
      "3. Facial Recognition is about identifying a person's identity based on their face. How do you think this could be used in real-world applications, like authentication or verification?\n",
      "\n",
      "Also, I'd love to know more about the different techniques and algorithms that are used in computer vision, such as deep learning models. Are these similar to machine learning models, and if so, how do they differ?\n",
      "Claude 3.5 Haiku:\n",
      "Fantastic questions! I'll break down each of your inquiries comprehensively:\n",
      "\n",
      "1. Image Classification Examples:\n",
      "- Medical Diagnosis\n",
      "  * Detecting cancer in X-rays\n",
      "  * Identifying skin lesions\n",
      "- Agriculture\n",
      "  * Classifying plant diseases\n",
      "  * Assessing crop health\n",
      "- Retail\n",
      "  * Product categorization\n",
      "  * Quality control\n",
      "- Wildlife Conservation\n",
      "  * Species identification\n",
      "  * Animal population tracking\n",
      "\n",
      "2. Self-Driving Car Object Detection:\n",
      "Critical Objects to Detect:\n",
      "- Lane Lines ✓ \n",
      "- Pedestrians ✓\n",
      "- Other Vehicles\n",
      "- Traffic Signs\n",
      "- Road Obstacles\n",
      "- Traffic Lights\n",
      "- Cyclists\n",
      "- Road Markings\n",
      "\n",
      "Detection Techniques:\n",
      "- Convolutional Neural Networks (CNNs)\n",
      "- YOLO (You Only Look Once) algorithm\n",
      "- Region-based CNN (R-CNN)\n",
      "\n",
      "3. Facial Recognition Applications:\n",
      "Authentication:\n",
      "- Smartphone unlocking\n",
      "- Airport security\n",
      "- Building access control\n",
      "\n",
      "Verification:\n",
      "- Bank transactions\n",
      "- Identity verification\n",
      "- Passport control\n",
      "\n",
      "Algorithms Used:\n",
      "- Deep Learning Models\n",
      "- Siamese Neural Networks\n",
      "- FaceNet\n",
      "- DeepFace\n",
      "\n",
      "Would you like me to elaborate on any of these points or dive deeper into the technical aspects?\n",
      "Llama 3.2:\n",
      "I'm loving this level of detail!\n",
      "\n",
      "Just to make sure I understand, let's break down each point further:\n",
      "\n",
      "1. Image Classification Examples:\n",
      "You mentioned some specific examples of image classification tasks in medical diagnosis, agriculture, retail, and wildlife conservation. Can you tell me more about how these applications are using computer vision to analyze images? For example, what kind of data is being used, like X-rays or satellite imagery?\n",
      "2. Self-Driving Car Object Detection:\n",
      "You listed some critical objects that self-driving cars might need to detect for safe navigation. What's the current state-of-the-art in object detection techniques for self-driving cars? Are there any specific challenges you're facing, like handling occlusions or varying lighting conditions?\n",
      "3. Facial Recognition Applications:\n",
      "I'm curious about the different types of facial recognition applications you mentioned (authentication, verification). Can you elaborate on how these are being used, like bank transactions or passport control? What kind of data is being used to train these models, and what kind of accuracy can we expect?\n",
      "\n",
      "Also, I'd love to know more about the technical aspects of deep learning models and other computer vision techniques. How do they work, and what's the current state-of-the-art in terms of performance and efficiency?\n",
      "\n",
      "Lastly, you mentioned some algorithms like Siamese Neural Networks and FaceNet. Can you explain how these are being used for facial recognition applications? What's the difference between these algorithms and others, and why are they useful?\n",
      "Claude 3.5 Haiku:\n",
      "Phenomenal follow-up questions! I'll break this down comprehensively:\n",
      "\n",
      "1. Image Classification Data Types:\n",
      "Medical Imaging:\n",
      "- X-rays\n",
      "- MRI Scans\n",
      "- Ultrasound Images\n",
      "- Microscopic Tissue Samples\n",
      "\n",
      "Data Processing:\n",
      "- Pixel-level feature extraction\n",
      "- Convolutional Neural Networks (CNNs)\n",
      "- Training on labeled medical datasets\n",
      "\n",
      "Agriculture Imaging:\n",
      "- Satellite/Drone Imagery\n",
      "- High-resolution crop photographs\n",
      "- Spectral analysis techniques\n",
      "- Machine learning models\n",
      "\n",
      "2. Self-Driving Car Detection Challenges:\n",
      "\n",
      "Technical Challenges:\n",
      "- Occlusion handling\n",
      "- Low-light conditions\n",
      "- Weather variations\n",
      "- Complex urban environments\n",
      "\n",
      "Current State-of-the-Art:\n",
      "- YOLO v5/v7 algorithms\n",
      "- Transformer-based detection models\n",
      "- Sensor fusion (LIDAR + Camera)\n",
      "- Real-time processing (<50ms)\n",
      "\n",
      "Accuracy Metrics:\n",
      "- mAP (mean Average Precision)\n",
      "- Current top models: 85-92% accuracy\n",
      "\n",
      "3. Facial Recognition Technical Deep Dive:\n",
      "\n",
      "Authentication Techniques:\n",
      "- Siamese Neural Networks\n",
      "- Triplet Loss functions\n",
      "- Feature vector comparisons\n",
      "- Embedding space mapping\n",
      "\n",
      "Performance Metrics:\n",
      "- Verification accuracy: 99.7%\n",
      "- False positive rate: <0.1%\n",
      "\n",
      "Training Data:\n",
      "- Diverse facial datasets\n",
      "- Labeled face images\n",
      "- Synthetic data augmentation\n",
      "\n",
      "Algorithms Comparison:\n",
      "\n",
      "| Algorithm | Strengths | Limitations |\n",
      "|-----------|-----------|-------------|\n",
      "| FaceNet | High accuracy | Computational expensive |\n",
      "| DeepFace | Fast processing | Less robust to variations |\n",
      "| Siamese Networks | Adaptable | Requires careful training |\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of these explanations?\n"
     ]
    }
   ],
   "source": [
    "llama_messages = [\"Hi\"]\n",
    "claude_messages = [\"Hello there, what would you like to learn today?\"]\n",
    "\n",
    "print(f'Ollama:\\n{ollama_messages[0]}')\n",
    "print(f'Claude:\\n{claude_messages[0]}')\n",
    "\n",
    "for _ in range(5):\n",
    "    llama_next = call_llama()\n",
    "    print(f'Llama 3.2:\\n{llama_next}')\n",
    "    llama_messages.append(llama_next)\n",
    "                           \n",
    "    claude_next = call_claude()\n",
    "    print(f'Claude 3.5 Haiku:\\n{claude_next}')\n",
    "    claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e651ad-85c8-45c7-ba83-f7c689080d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
